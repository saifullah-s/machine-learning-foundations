# Machine Learning - Foundational Projects

## Overview  
Numerous projects were completed, implementing foundational machine learning algorithms through which I gained a comprehensive understanding of the algorithms themselves, as well as their mathematical underpinnings. The projects involved building models from scratch, solidifying both theoretical knowledge along with practical coding and implementation proficiency.  

**Note**: The various notebooks and code are being revised and prepared for uploading to my portfolio.  

## Key Accomplishments and Projects  

### 1. Decision Tree (From Scratch)  
- Developed a decision tree classifier using foundational principles such as:
  - Entropy and Information Gain to determine optimal splits.
  - Recursive partitioning to create interpretable tree-based models.  
- Gained a deep understanding of how tree-based models can be adapted for classification and regression tasks.

### 2. K-Means Clustering (From Scratch)  
- Implemented the K-Means algorithm to cluster unlabeled data into distinct groups by:
  - Iteratively calculating centroids.
  - Assigning data points to the nearest centroid.
- Explored the trade-offs of choosing the number of clusters (k) using techniques like the Elbow Method.

### 3. Anomaly Detection (From Scratch)  
- Built an anomaly detection system to identify outliers in datasets, using Gaussian distributions and probability thresholds.
- Applied this technique to detect irregularities in real-world scenarios, such as failing system servers.

### 4. Recommender Systems  
- Implemented two types of recommender systems:
  - Collaborative Filtering: Using user-item interaction matrices to suggest personalized recommendations based on user behavior.
  - Content-Based Filtering: Using item attributes to recommend similar items to users.
- Understood how these techniques power modern recommendation engines (Netflix, Amazon, and others).

### 5. Principal Component Analysis (PCA)  
- Applied PCA for dimensionality reduction and improving computational efficiency.
- Learned how to retain the most informative features while minimizing information loss.

## Additional Skills Acquired
- Comprehensive understanding of Linear Regression, Logistic Regression, and their mathematical underpinnings.
- Hands-on experience with Gradient Descent for optimizing models.
- Proficiency in Feature Scaling and Feature Engineering.
- Practical exposure to real-world datasets, including preprocessing, cleaning, and visualization techniques.

## Tools and Libraries Used  
- Programming Language: Python  
- Libraries: NumPy, Pandas, Matplotlib, Scikit-learn  
- Environment: Jupyter Notebook

## Impact and Takeaways  
These projects equipped me with the technical knowledge and practical experience to implement and deploy machine learning solutions. By building models from scratch and understanding their inner workings, I gained a solid foundation for tackling complex ML problems and adapting algorithms to real-world challenges.
